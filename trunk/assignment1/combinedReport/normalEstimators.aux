\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{yamazaki98introduction}
\@writefile{toc}{\contentsline {section}{\numberline {2}Mathematical Overviews}{5}}
\newlabel{math-overview-section}{{2}{5}}
\citation{moon-stirling-book}
\newlabel{typical-scatter}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Principal Components}{6}}
\newlabel{pca-sub-section}{{2.1}{6}}
\newlabel{pca-characteristic}{{3}{6}}
\newlabel{pca-optimization-definition}{{4}{7}}
\newlabel{pca-optimization-derivation}{{5}{7}}
\citation{apple-accelerate-framework}
\newlabel{data-by-principal-component}{{7}{8}}
\newlabel{principal-component}{{8}{8}}
\newlabel{data-by-principal-component-eigenvector}{{9}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Gram-Schmidt Orthogonalization}{9}}
\citation{schaums-linear-algebra}
\newlabel{gso-theorem}{{2.1}{10}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gram Schmidt Orthogonalization}}{10}}
\newlabel{alg:gso}{{1}{10}}
\citation{schaums-linear-algebra}
\citation{schaums-linear-algebra}
\citation{apple-accelerate-framework}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Eigenvalues: Characteristic Polynomials}{11}}
\newlabel{eigenvalueDefinition}{{2.3}{11}}
\newlabel{eigenvalueCharacteristicEquation}{{13}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Multiple Discriminant Analysis}{12}}
\newlabel{mda-description-subsection}{{2.2}{12}}
\newlabel{total-within-scatter-matrix}{{14}{12}}
\citation{duda-hart-stork}
\citation{duda-hart-stork}
\citation{duda-hart-stork}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Expected Maximization}{13}}
\newlabel{em-description-subsection}{{2.3}{13}}
\newlabel{em_basis}{{15}{13}}
\newlabel{duda-hart-stork-EM}{{16}{13}}
\citation{yamazaki98introduction}
\newlabel{expectedMatrix}{{17}{14}}
\citation{appo-ica-book}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Expectation Maximization: This algorithm satisfies the EM constraints specified in equations 16\hbox {} and 15\hbox {}.}}{16}}
\newlabel{alg:expectation-maximization}{{2}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Independent Component Analysis Family of Estimators}{16}}
\newlabel{mutual-independence}{{3}{16}}
\newlabel{standardICA}{{22}{16}}
\newlabel{standardICANoiseless}{{23}{16}}
\newlabel{standardICAInverse}{{24}{16}}
\newlabel{unwhitenedICA}{{25}{17}}
\newlabel{whitenedICs}{{28}{17}}
\newlabel{kurtosisStandardWhite}{{29}{17}}
\newlabel{kurtosisStandardWhiteAssumed}{{30}{17}}
\newlabel{addKurtosis}{{31}{18}}
\newlabel{scaleKurtosis}{{32}{18}}
\newlabel{kurtosisAppliedToICACharacter}{{33}{18}}
\newlabel{consequenceOfICACharacter}{{34}{18}}
\newlabel{icAssumptionUnitCircle}{{35}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Kurtosis Gradient Maximization}{18}}
\citation{appo-ica-book}
\newlabel{kurtosis-vec-prod}{{37}{19}}
\newlabel{kurtosis-vec-prod-to-zero}{{40}{19}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Projection Pursuit}}{19}}
\newlabel{alg:Projection-Pursuit}{{3}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Non-normality by Negentropy}{20}}
\newlabel{whitenedNegentropyEstimation}{{41}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Negentropy Gradient Algorithm}{20}}
\newlabel{nonPolynomialApproximationNegentropy}{{42}{20}}
\newlabel{normalConstraintOnMixer}{{45}{21}}
\newlabel{directionNegentropyNonPoly}{{47}{21}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces FastICA Stochastic Negentropy Projection Pursuit}}{21}}
\newlabel{alg:FastICA-Stochastic-Negentropy-Projection-Pursuit}{{4}{21}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces FastICA Negentropy Projection Pursuit}}{21}}
\newlabel{alg:FastICA-Negentropy-Projection-Pursuit}{{5}{21}}
\citation{appo-ica-book}
\citation{appo-ica-book}
\@writefile{toc}{\contentsline {section}{\numberline {4}Sparse Coding Shrinkage}{22}}
\newlabel{sparse-coding-shrinkage}{{4}{22}}
\newlabel{image_character}{{48}{22}}
\citation{appo-ica-book}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Insert and Remove Noise on Patch Oriented Sparse Coding \\Shrinkage}{23}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Insert and Remove Noise on Neighborhood Oriented Sparse Coding Shrinkage}}{23}}
\newlabel{alg:patch-oriented-sparse-coding-shrinkage-with-source}{{6}{23}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Neighborhood Oriented Source De-constructor}}{24}}
\newlabel{alg:Patch-Oriented-Source-Builder}{{7}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Connection between Independent Component Analysis and Sparse Code Shrinkage}{24}}
\newlabel{ica-scs-connection}{{4.2}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Mathematica implementation of Multiple Discriminant \\Analysis}{25}}
\newlabel{mathematica-prototype-mda}{{5}{25}}
\newlabel{mathematica_system}{{49}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Mathematica Plots using a manual MDA}}{27}}
\newlabel{mathematicaPlotsUsingManualMDA}{{1}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Evolution of CPU Bound Solutions}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Octave and Core Graphics Implementation of Expected Maximization}{28}}
\newlabel{classic-em-implementation}{{6.1}{28}}
\newlabel{sum-of-probabilities}{{50}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This figure is a plot of Guassian sums for the optic disc.}}{28}}
\newlabel{histogram-optic-disc}{{2}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces This is a plot of sub-Gaussian components for the optic disc.}}{29}}
\newlabel{histograms-optic-disc}{{3}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Core Graphics Version}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The results of an ``EM for Image'' are a set of segmenting classifiers and the masks that result from the classification}}{30}}
\newlabel{emComponentSelection}{{4}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces EM Segments shown by mean and variance for a photo of a human iris.}}{30}}
\newlabel{segmentsPanel}{{5}{30}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}First Successful GUI Model}{31}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.3}Design Details and Considerations}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Principal Component Anaylsis}{34}}
\newlabel{pca-classic-implementation}{{6.2}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Both the original image and 5 EM Segments of a human iris. }}{35}}
\newlabel{fiveEmSegments}{{6}{35}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Unit Test of PCA}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}A Quartz Composer Model - CPU Bound}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A Quartz Composer patch for computing PCA via EVD.}}{40}}
\newlabel{downsampled-pca-quartz-composer}{{7}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces This is a set of results of a Quartz Composition PCA-Downsample of PCA via EVD. In this sample, a few of the upper half principal components are shown.}}{40}}
\newlabel{downsampled-pca-quartz-composer-lower-red-channel-eye}{{8}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces This is a set of results of a Quartz Composition PCA-Downsample of PCA via EVD. In this sample, the green channel is used to provide the filter, and an enhancement is made on the filter elements themselves. }}{41}}
\newlabel{downsampled-pca-quartz-composer-green-channel-blended}{{9}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces This is a set of results of a Quartz Composition PCA-Downsample of PCA via EVD. In this sample, the red channel is used with an enhancement. These elements come from the lower principal components. }}{41}}
\newlabel{downsampled-pca-quartz-composer-green-channel-blended}{{10}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Filters using ICA and PCA}{42}}
\newlabel{transformation-masking-maps}{{6.3}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {7}A Core Image Innovation}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A Quartz Composer patch for computing PCA via EVD.}}{43}}
\newlabel{downsampled-pca-quartz-composer}{{11}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces This is a set of results of a Quartz Composition of a ICA-Downsample. In this sample, the red channel is the primary source for the PCA-ICA estimator. On the left, an edge filter is applied before the image is channelled into the PCA-ICA estimator. The results are multiply blended with the original image. On the right, the original image is multiply blended with the PCA-ICA estimation. }}{44}}
\newlabel{downsampled-ica-quartz-composer-red-channel}{{12}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Pseudo Zero Branch Program Model}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Core Image Kernel Model}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Constructing Where Size and Position Matters}{48}}
\newlabel{cifiltergenerator}{{7.3}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}GSO version of PCA using the Core Image Kernel Model}{49}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Neighborhood Orientation to Linear Algebra}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces These are the core filters required for GSO. They are computing in this case by a pseudo-algebra called in this report neighborhood algebra. }}{50}}
\newlabel{qc-gso-fundamental-core}{{13}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces This diagram shows the arrangement of neighborhoods in a neighborhood mixing image. }}{50}}
\newlabel{neighborhoodArrangement}{{14}{50}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Reductions resulting from ``Neighborhood Algebra''}{51}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces This diagram shows the connection of fundamental kernels to form a neighborhood sum kernel. }}{52}}
\newlabel{neighborhoodSum}{{15}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces This diagram shows the connection of fundamental kernels to form a neighborhood mean kernel. }}{52}}
\newlabel{neighborhoodMean}{{16}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Debugging GPU-bound products using Quartz Composer}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces This diagram shows the connection of fundamental kernels to form a neighborhood inner product kernel. }}{53}}
\newlabel{neighborhoodInnerProduct}{{17}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces This diagram shows the connection of fundamental kernels to form a neighborhood norms kernel. }}{53}}
\newlabel{neighborhoodNorms}{{18}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces This diagram shows the connection of fundamental kernels to form a neighborhood subtract kernel. }}{53}}
\newlabel{gsoSubtract}{{19}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces This diagram shows the connection of fundamental kernels to form a neighborhood ICA kernel. }}{54}}
\newlabel{neighborhoodICA}{{20}{54}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Excessive Handlers: Debugging the generator and filters}{55}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}Reducing debugging problems by using QC-Plug-in to Control the Loop}{56}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces This diagram shows the collection of QC patches computing GSO using a feedback control patch. Called DCQCIInnerProductLoop in these diagrams, the control patch provides a mechanism for feedback to build a solution for the PCA mixing matrix. This approach empowers QC to provide prototyping tool for GPU bound solutions.}}{57}}
\newlabel{controlLoopGSO}{{21}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Accelerate Construction using NSOperation}{58}}
\newlabel{nsoperation-for-cifilter-generator}{{7.6}{58}}
\@writefile{toc}{\contentsline {section}{\numberline {A}A Listing Mathematica Implementation for the Iris Data-set}{59}}
\newlabel{listing-mathematica-iris}{{A}{59}}
\@writefile{lol}{\contentsline {lstlisting}{language=Mathematica}{59}}
\@writefile{toc}{\contentsline {section}{\numberline {B}A Listing of the Objective-C version of EM}{61}}
\newlabel{lst_initializeEM}{{1}{61}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Initialize EM}{61}}
\newlabel{lst_estimationStepEM}{{2}{63}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Estimation step of EM, computed explicitly in Objective C}{63}}
\newlabel{lst_maximizationStepEM}{{3}{65}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}Maximization step of EM, computed explicitly in Objective C}{65}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Implementation of Projection Pursuit}{67}}
\newlabel{lst_projectionPursuitApply}{{4}{67}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}Projection Pursuit in Objective C}{67}}
\newlabel{lst_ZeroMeanMultivariate}{{5}{69}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}Zero Mean Multivariate in Objective C}{69}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Core Image Filters Developed for Conventional Linear Algebra}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Image Add Image}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Image Add Scalar}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.3}Image Column Dot Product No Scale}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.4}Image Column Multiply}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.5}Image Determinant Unit}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.6}Image Determinant Column}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.7}Image Divide Scalar}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.8}Image Dot Divide Image}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.9}Image Dot Multiply Image}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.10}Image Dot Square Root}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.11}Image Identity}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.12}Image Zeroes}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.13}Image Inner Product and Norm Multiplication}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.14}Image Maximum Unit}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.15}Image Multiply Scalar}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.16}Image Multiply Image Unit (Standard)}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.17}Image Subtract Image}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.18}Image Subtract Scalar}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.19}Image Trace Unit}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.20}Image Transpose}{72}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Neighbor Algebra Notes}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Equivalent Transpose}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Region Of Interest Extractor}{74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.3}Outer Product}{74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.4}Samples Every So Many}{74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.5}Dot multiply and Add}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Theory of Estimators}{74}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Estimators (ICA) Framework}}{74}}
\newlabel{fig-estimator-world}{{22}{74}}
\newlabel{estimatorDefinition}{{F.1}{74}}
\citation{appo-ica-book}
\citation{appo-ica-book}
\newlabel{unbiasedEstimator}{{69}{75}}
\newlabel{unbiasedEstimatorGiven}{{70}{75}}
\newlabel{lossFunctionDefition}{{F.2}{75}}
\citation{appo-ica-book}
\citation{appo-ica-book}
\citation{appo-ica-book}
\newlabel{efficientEstimatorDefinition}{{F.3}{76}}
\newlabel{cramerRaoLowerBound}{{F.4}{76}}
\citation{appo-ica-book}
\citation{wolfram-mathworld-least-squares}
\newlabel{robustnessDefinition}{{F.5}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F.1}Least Squares}{77}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces Least Squares Estimation (Regression) derived from definition found at \cite  {wolfram-mathworld-least-squares}.}}{78}}
\newlabel{alg:least-squares}{{8}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F.2}Maximum a Posteriori}{78}}
\newlabel{bayesTheorem}{{77}{78}}
\citation{appo-ica-book}
\newlabel{ln_bayes}{{83}{79}}
\@writefile{toc}{\contentsline {section}{\numberline {G}Entropy and Mutual Information: Determining Independence}{80}}
\newlabel{entropy}{{G}{80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {G.1}Measures of Information}{80}}
\citation{moon-stirling-book}
\@writefile{toc}{\contentsline {subsection}{\numberline {G.2}Theory of Maximizing Representation}{82}}
\newlabel{maximizing-represnetation}{{G.2}{82}}
\newlabel{constant-entropy}{{90}{82}}
\newlabel{regularity-condition-constraint-for-entropy}{{91}{82}}
\newlabel{system-regularity-condition-constraint-for-entropy}{{92}{82}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {G.2.1}Negentropy}{82}}
\newlabel{maximizing-via-negentropy}{{G.2.1}{82}}
\newlabel{negentropyGauss}{{93}{82}}
\newlabel{normalEntropy}{{94}{82}}
\citation{appo-ica-book}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {G.2.2}Approximation by Cummulants}{83}}
\newlabel{standardized-Gaussian}{{95}{83}}
\newlabel{standardized-Gaussian-first-derivative}{{95}{83}}
\bibdata{../../patternNotes.bib}
\bibstyle{abbrv}
